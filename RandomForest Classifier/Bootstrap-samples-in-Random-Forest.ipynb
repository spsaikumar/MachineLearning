{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNKZq4XrXQh"
      },
      "source": [
        "# <font color='red'><b>Bootstrap assignment</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAHap1Z3FZC-"
      },
      "source": [
        "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
        "\n",
        "Every Grader function has to return True.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QAh-jSMG2O-v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxBq_bvrwh2"
      },
      "source": [
        "<font color='blue'> <b>Importing packages</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m6ag91ijrQOs"
      },
      "outputs": [],
      "source": [
        "import numpy as np # importing numpy for numerical computation\n",
        "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
        "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcHOsONTt1K_"
      },
      "outputs": [],
      "source": [
        "boston = load_boston()\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc1htEFYuLRj",
        "outputId": "a030b1c0-12aa-4146-943a-b0d92494d7d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFU1njkjHmjA",
        "outputId": "f7941d21-0499-49fb-b4a6-7746c6be3910"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQle3T_wuOa3",
        "outputId": "b9f840ef-f9df-44c5-c406-53a220e1db08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
              "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
              "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
              "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
              "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOirww5U-peZ",
        "outputId": "55d273ca-31fb-40c2-ed6e-7e93f5682f88"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 33.4, 36.2])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEa_HqRZloH4"
      },
      "source": [
        "## <font color='red'><b>Task 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5q8IxHNRk3"
      },
      "source": [
        "<font color='red'> <b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCFCaOzl7Mr"
      },
      "source": [
        "*  <font color='blue'><b>Creating samples</b></font><br>\n",
        "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
        "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
        "    \n",
        "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
        "* <font color='blue'><b> Create 30 samples </b></font>\n",
        "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
        "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
        "Make sure each sample will have atleast 3 feautres/columns/attributes\n",
        "\n",
        "* <font color='red'><b> Note - While selecting the random 60% datapoints from the whole data, make sure that the selected datapoints are all exclusive, repetition is not allowed. </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqFEBSvNjCa"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi9AhCYNq3Z"
      },
      "source": [
        "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLBnZHXOFln"
      },
      "source": [
        "*  Build a regression trees on each of 30 samples.\n",
        "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
        "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls23JLnSN23"
      },
      "source": [
        "<font color='red'> <b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2GchkGSWnh"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the OOB score </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHkVV2kSibm"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK860ocxTyoz"
      },
      "source": [
        "# <font color='red'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dme-N6TUCrY"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UcH1x9Uwrj"
      },
      "source": [
        "# <font color='red'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOC_AgsLU7OH"
      },
      "source": [
        "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs5jSFdVILe"
      },
      "source": [
        "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "Predict the house price for this point as mentioned in the step 2 of Task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6rShd89t552"
      },
      "source": [
        "## <font color='red'><b>A few key points</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdgTUXTouHEd"
      },
      "source": [
        "* Remember that the datapoints used for calculating MSE score contain some datapoints that were initially used while training the base learners (the 60% sampling). This makes these datapoints partially seen (i.e. the datapoints used for calculating the MSE score are a mixture of seen and unseen data).\n",
        "Whereas, the datapoints used for calculating OOB score have only the unseen data. This makes these datapoints completely unseen and therefore appropriate for testing the model's performance on unseen data.\n",
        "\n",
        "* Given the information above, if your logic is correct, the calculated MSE score should be less than the OOB score.\n",
        "\n",
        "* The MSE score must lie between 0 and 10.\n",
        "* The OOB score must lie between 10 and 35.\n",
        "\n",
        "* The difference between the left nad right confidence-interval values must not be more than 10. Make sure this is true for both MSE and OOB confidence-interval values."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eOF53MZk4gXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fHTdS_zpgG"
      },
      "source": [
        "# <font color='blue'> <b>Task - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yGBuryOwHz"
      },
      "source": [
        "<font color='blue'><b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJXX8vf3z073"
      },
      "source": [
        "*  <font color='blue'> <b>Creating samples</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVaWG1F4uCZ"
      },
      "source": [
        "<font color='Orange'><b>Algorithm</b></font>\n",
        "\n",
        "![alt text](https://i.imgur.com/OfcFrUP.jpg/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_oWoN97BhDY"
      },
      "source": [
        "*  <font color='blue'><b> Write code for generating samples</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n"
      ],
      "metadata": {
        "id": "joWJ8R_0M4f0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ph_6D2SDzz7F"
      },
      "outputs": [],
      "source": [
        "def generating_samples(input_data, target_data):\n",
        "\n",
        "    '''In this function, we will write code for generating 30 samples '''\n",
        "    # you can use random.choice to generate random indices without replacement\n",
        "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
        "    # Please follow above pseudo code for generating samples \n",
        "    selected_rows = np.random.choice(len(input_data), 303, replace = False)\n",
        "    selected_rows = np.sort(selected_rows)\n",
        "\n",
        "\n",
        "    replaced_rows = np.random.choice(selected_rows, 203, replace = False)\n",
        "    replaced_rows = np.sort(replaced_rows)\n",
        "\n",
        "    selected_columns = np.sort(np.random.choice(input_data.shape[1], size=random.randint(3, input_data.shape[1]), replace =False))\n",
        "    \n",
        "    sample_data = input_data[selected_rows[:,None],selected_columns]\n",
        "    target_sameple_data = target_data[selected_rows]\n",
        "\n",
        "    replicating_data = input_data[replaced_rows[:,None],selected_columns]\n",
        "    target_replicating_data = target_data[replaced_rows]\n",
        "\n",
        "    sampled_input_data = np.vstack((sample_data, replicating_data))\n",
        "    sampled_target_data = np.vstack((target_sameple_data.reshape(-1,1),target_replicating_data.reshape(-1,1)))\n",
        "\n",
        "    return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
        "    #note please return as lists\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MivEQFlm7iOg"
      },
      "source": [
        "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AVvuhNzm7uld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffe3ca2-b9a9-44b6-d76c-fbc4e7fe4f59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def grader_samples(a,b,c,d):\n",
        "    length = (len(a)==506  and len(b)==506)\n",
        "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
        "    rows_length = (len(c)==303)\n",
        "    column_length= (len(d)>=3)\n",
        "    assert(length and sampled and rows_length and column_length)\n",
        "    return True\n",
        "a,b,c,d = generating_samples(x, y)\n",
        "grader_samples(a,b,c,d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4LSsmn4Jn2_"
      },
      "source": [
        "*  <font color='blue'> <b>Create 30 samples </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec7MN6sL2BZ"
      },
      "source": [
        "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1flUzbUjlFh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "XXlKWjCcBvTk"
      },
      "outputs": [],
      "source": [
        "# Use generating_samples function to create 30 samples \n",
        "# store these created samples in a list\n",
        "list_input_data =[]\n",
        "list_output_data =[]\n",
        "list_selected_row= []\n",
        "list_selected_columns=[]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,30):\n",
        "  sampled_input_data, sampled_target_data, selected_rows, selected_columns = generating_samples(x,y)\n",
        "  #grader_samples(final_sample_data , final_target_data,selected_rows,selected_columns)\n",
        "  # Append the info in the respective list.\n",
        "  list_input_data.append(sampled_input_data)\n",
        "  list_output_data.append(sampled_target_data)\n",
        "  list_selected_row.append(selected_rows)\n",
        "  list_selected_columns.append(selected_columns)"
      ],
      "metadata": {
        "id": "2_g-qY7ilHao"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUz9VFiMQkh"
      },
      "source": [
        "<font color='cyan'> <b>Grader function - 2 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "hCvIq8NuMWOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87d5c8f-9683-4083-bba4-3345c687eb91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "def grader_30(a):\n",
        "    assert(len(a)==30 and len(a[0])==506)\n",
        "    return True\n",
        "grader_30(list_input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pv-mkZkO6dh"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whaHCPB0O8qF"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy4zXSWPtU8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for building tree</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvH06HPQBdP"
      },
      "source": [
        "![alt text](https://i.imgur.com/pcXfSmp.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwPO_uHQjul"
      },
      "source": [
        "*  <font color='blue'><b> Write code for building regression trees</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "YWQp6tRwMthq"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor \n",
        "list_of_all_models = []\n",
        "for i in range(0, 30):\n",
        "  input_data = list_input_data[i]\n",
        "  target_data = list_output_data[i]\n",
        "  classifier = DecisionTreeRegressor(max_depth=None,min_samples_split=2) \n",
        "  classifier.fit(input_data, target_data) \n",
        "  list_of_all_models.append(classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21j8BKfAQ1U8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0mTBD2RBx_"
      },
      "source": [
        "![alt text](https://i.imgur.com/sPEE618.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-UamlHRjPy"
      },
      "source": [
        "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIMT7_oR312"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig8PTgdVntdC",
        "outputId": "6ab1a2e4-1698-46ad-bbb2-91487233dbc2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "qWhcvMRWRA9b"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "\n",
        "list_y_predict = []\n",
        "for i in range(0,30):\n",
        "  pred_y = list_of_all_models[i].predict(x[:,list_selected_columns[i]]) \n",
        "  list_y_predict.append(pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_y_predict[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3zGx3RloUxh",
        "outputId": "1169bbd3-882b-42bb-ae9c-29d33311d841"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "506"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_y_predict[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z60VRB5Jod3p",
        "outputId": "1ee94a1e-6edc-46a8-90e9-6627d9780554"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 48.5, 36.2, 28.7, 20.1, 27.1, 16.5, 18.9, 15. ,\n",
              "       23.1, 21.7, 19.6, 18.2, 24.3, 20.6, 19.6, 20.2, 18.2, 13.6, 19.6,\n",
              "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 20.2, 12.7, 19.6, 13.2,\n",
              "       13.1, 13.1, 18.9, 20. , 21. , 24.7, 30.8, 44. , 31.1, 25.3, 24.7,\n",
              "       21.2, 19.3, 19.3, 16.6, 18.7, 19.4, 22.5, 20.5, 25. , 19.8, 18.9,\n",
              "       27.9, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 23.9, 25. , 28.7, 23.5,\n",
              "       24. , 18.2, 17.4, 20.9, 22.6, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "       20. , 21.2, 23.7, 28. , 23.9, 23.2, 22.9, 18.7, 26.6, 22.5, 22.2,\n",
              "       23.6, 28.7, 19.8, 22. , 22.9, 28.7, 19.5, 28.4, 21.4, 44.8, 43.8,\n",
              "       33.2, 23.7, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 20.1, 19.4,\n",
              "       21.7, 22.8, 23.1, 18.7, 19.2, 17.6, 21.2, 19.2, 20.4, 19.3, 29.6,\n",
              "       21.4, 17.3, 17.3, 17.3, 21.4, 17.8, 16.2, 18. , 15.6, 19.2, 23.8,\n",
              "       18.2, 18. , 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 13.3, 13.3, 27.1,\n",
              "       27.1, 27.1, 17.8, 17.8, 14.6, 17.8, 17.8, 19.6, 19.6, 23.8, 19.6,\n",
              "       17.4, 15.6, 15.6, 21.9, 24.3, 23.3, 27. , 50. , 50. , 50. , 24.3,\n",
              "       25. , 50. , 23.8, 22.3, 22.3, 17.4, 19.1, 23.1, 23.6, 26.7, 29.4,\n",
              "       22. , 24.6, 29.9, 28.4, 33.4, 28.4, 32.5, 32.5, 26.4, 29.6, 50. ,\n",
              "       24.6, 29.8, 30.5, 31.2, 30.5, 36.4, 31.1, 29.1, 44. , 33.3, 30.3,\n",
              "       43.1, 34.9, 29.1, 24.1, 44. , 48.5, 48.5, 19.3, 24.4, 18.5, 24.4,\n",
              "       27.1, 23.1, 19.3, 19.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "       26.7, 21.7, 24. , 23.9, 44.8, 31.1, 50. , 24.8, 46.7, 31.5, 24.3,\n",
              "       31.7, 50. , 48.3, 23.6, 24. , 25.1, 31.1, 23.7, 23.3, 22. , 20.1,\n",
              "       22. , 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 26.2, 42.8, 42.8,\n",
              "       42.8, 21.9, 22. , 44. , 50. , 36.5, 50. , 33.8, 43.1, 43.1, 31. ,\n",
              "       36.5, 31. , 30.7, 50. , 43.5, 23.3, 18.7, 24.4, 24.4, 24.4, 32.4,\n",
              "       43.8, 24.7, 28.5, 29.1, 35.1, 48.5, 35.4, 48.5, 50. , 19.4, 22. ,\n",
              "       22.5, 23.2, 23.8, 20.5, 28.5, 37.3, 27.9, 20.9, 21.7, 23.2, 27.1,\n",
              "       20.3, 22.5, 23.7, 24.8, 22. , 26.4, 31.1, 35.4, 28.4, 33.4, 28.2,\n",
              "       22.8, 22.8, 16.1, 22.1, 19.1, 23.6, 23.8, 16.2, 14.6, 19.4, 23.1,\n",
              "       18.7, 23.8, 23.8, 23.8, 18.5, 25. , 24.6, 26.2, 18.7, 24. , 22.6,\n",
              "       19.8, 17.2, 19.4, 26.6, 26.6, 21.6, 19.5, 18.5, 22. , 18.7, 18.7,\n",
              "       32.7, 22. , 23.9, 31.2, 17.5, 17.2, 23.1, 23.1, 26.6, 22.9, 24.1,\n",
              "       23.7, 30.1, 18.2, 20.6, 15.1, 19.6, 22.7, 19.1, 21.4, 19.9, 20.8,\n",
              "       19.9, 21.9, 23.3, 21.9, 27.9, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "       13.8, 15. , 13.9, 13.3, 10.9, 11.9,  9.6, 10.9, 12.3, 12.3,  8.8,\n",
              "        7.2, 10.5,  7.4,  7.2, 13.3, 15.1, 23.2,  9.7, 15.1, 12.7, 13. ,\n",
              "       12.5,  8.5,  7.4,  6.3,  5.6, 11.9, 12.1,  8.3,  5.6, 16.3, 11.9,\n",
              "       27.9,  9.7, 27.5, 27.9,  8.4,  7.2, 16.3, 13.8,  7.2,  8.7,  5.6,\n",
              "        8.8,  8.4, 27.9, 15.1, 12.7,  8.4, 11.7,  9.5, 10.2, 10.2, 11. ,\n",
              "        9.5, 15.1, 14.1, 16.1, 16.1, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "       10.5, 14.1, 18.4, 27.5, 10.8,  9.5, 14.1, 14.6, 13. , 13. , 13.4,\n",
              "       14.1, 17.4, 27.5, 14.9, 14.1, 12.7, 13.5, 15.1, 20. , 16.4, 17.7,\n",
              "       19.5, 20.2, 11.7, 23.2, 16.4, 12.7,  9.6, 20.1, 19.9, 19.6, 23.2,\n",
              "       29.8, 14.9, 13.1, 16.7, 10.9, 14.6, 12.7, 23. , 23.7, 25. , 21.8,\n",
              "       20.6, 21.8, 19.1, 21.8, 15.2, 13.1,  8.1, 13.6, 20.1, 21.8, 19.2,\n",
              "       23.1, 18.7, 16.8, 19.3, 17.5, 16.8, 22.4, 20.6, 29.1, 22. , 20.6])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating median for each data point from predicted y of each model\n",
        "final_y_predict = [] \n",
        "\n",
        "for i in range(0, len(x)):\n",
        "  median_y = []\n",
        "  for j in range(0, 30):\n",
        "    median_y.append(list_y_predict[j][i]) \n",
        "  median_ = statistics.median(median_y) \n",
        "  final_y_predict.append(median_)"
      ],
      "metadata": {
        "id": "FlTKw0h7n8N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating MSE :\n",
        "from sklearn.metrics import mean_squared_error \n",
        "mse = mean_squared_error(y, final_y_predict) \n",
        "print(\"=\" * 50)\n",
        "print(\"MSE on train data set : \" , mse) \n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsXuzAUzmsfS",
        "outputId": "6a60fcf3-dde3-40e6-9995-c57b69637942"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "MSE on train data set :  0.0338586956521739\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuclPDMnSz8F"
      },
      "source": [
        "<font color='blue'><b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESb9FSIDTM5V"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB-d6NMETbd9"
      },
      "source": [
        "![alt text](https://i.imgur.com/95S5Mtm.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW3GOcFzTqbt"
      },
      "source": [
        "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqcS03pUYSZ"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_sample_predict = []\n",
        "pred_y = list_of_all_models[1].predict(x[0][list_selected_columns[1]].reshape(1,-1)) \n",
        "y_sample_predict.append(pred_y[0])"
      ],
      "metadata": {
        "id": "2f72ht0xrOGN"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0][list_selected_columns[1]].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EaUmNFJrYFJ",
        "outputId": "552806eb-011f-44ed-f3a7-fcc3225da996"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0][list_selected_columns[1]].reshape(1,-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y6UNU4vr_4k",
        "outputId": "63f6032e-e204-42e9-d9cf-7e903fbe8a98"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmQ6gk4Fro1Z",
        "outputId": "763993cd-89cb-414b-e58f-452fbbe2f81c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = list_of_all_models[j].predict(x[0][list_selected_columns[j]].reshape(1,-1)) \n",
        "pred_y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTwLC-L2sjCp",
        "outputId": "f6a6e75a-00e3-4918-90ef-a9177ac1c42a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24.0"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Fog_6DNdS-h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469e1b7d-12f7-4a9f-ada8-977064e0edde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================\n",
            "OOBS Score :  11.253729518006153\n",
            "===================================\n"
          ]
        }
      ],
      "source": [
        "oob_y_predict = []\n",
        "y_sample_predict = []\n",
        "# iterating through each data point. \n",
        "for i in range (0,506):\n",
        "  data = x[i]\n",
        "  for j in range(0,30):#30\n",
        "    if i not in list_selected_row[j]:\n",
        "      pred_y = list_of_all_models[j].predict(data[list_selected_columns[j]].reshape(1,-1)) \n",
        "      y_sample_predict.append(pred_y[0])\n",
        "  y_sample_predict_oobs = statistics.median(y_sample_predict) \n",
        "  y_sample_predict.clear() \n",
        "  oob_y_predict.append(y_sample_predict_oobs)\n",
        "\n",
        "#print((oob_y_predict))\n",
        "#Calculate OObs score now :\n",
        "total_error = 0\n",
        "for i in range(0, 506):\n",
        "  error = y[i] - oob_y_predict[i] \n",
        "  error = error * error #Square error :\n",
        "  total_error = total_error + error \n",
        "oobs_score = total_error/506 \n",
        "print(\"=\" * 35)\n",
        "print(\"OOBS Score : \" , oobs_score) \n",
        "print(\"=\" * 35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuiwX3OUjUI"
      },
      "source": [
        "# <font color='blue'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "ceW5-D88Uswi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d6c3fd-c032-4414-a7cd-08613e88bb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Iteration:  1\n",
            "MSE on train data = 0.196\n",
            "OOBS Score =  14.501\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  2\n",
            "MSE on train data = 0.086\n",
            "OOBS Score =  16.666\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  3\n",
            "MSE on train data = 0.241\n",
            "OOBS Score =  13.803\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  4\n",
            "MSE on train data = 0.01\n",
            "OOBS Score =  14.063\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  5\n",
            "MSE on train data = 0.076\n",
            "OOBS Score =  14.177\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  6\n",
            "MSE on train data = 0.029\n",
            "OOBS Score =  11.661\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  7\n",
            "MSE on train data = 0.055\n",
            "OOBS Score =  14.547\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  8\n",
            "MSE on train data = 0.066\n",
            "OOBS Score =  12.253\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  9\n",
            "MSE on train data = 0.051\n",
            "OOBS Score =  13.699\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  10\n",
            "MSE on train data = 0.016\n",
            "OOBS Score =  13.21\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  11\n",
            "MSE on train data = 0.062\n",
            "OOBS Score =  12.837\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  12\n",
            "MSE on train data = 0.267\n",
            "OOBS Score =  15.574\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  13\n",
            "MSE on train data = 0.028\n",
            "OOBS Score =  15.608\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  14\n",
            "MSE on train data = 0.076\n",
            "OOBS Score =  14.805\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  15\n",
            "MSE on train data = 0.069\n",
            "OOBS Score =  16.16\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  16\n",
            "MSE on train data = 0.042\n",
            "OOBS Score =  11.722\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  17\n",
            "MSE on train data = 0.028\n",
            "OOBS Score =  14.221\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  18\n",
            "MSE on train data = 0.028\n",
            "OOBS Score =  10.136\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  19\n",
            "MSE on train data = 0.056\n",
            "OOBS Score =  15.767\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  20\n",
            "MSE on train data = 0.11\n",
            "OOBS Score =  14.838\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  21\n",
            "MSE on train data = 0.765\n",
            "OOBS Score =  13.19\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  22\n",
            "MSE on train data = 0.154\n",
            "OOBS Score =  11.249\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  23\n",
            "MSE on train data = 0.026\n",
            "OOBS Score =  13.21\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  24\n",
            "MSE on train data = 0.019\n",
            "OOBS Score =  16.87\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  25\n",
            "MSE on train data = 0.069\n",
            "OOBS Score =  12.7\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  26\n",
            "MSE on train data = 0.146\n",
            "OOBS Score =  15.621\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  27\n",
            "MSE on train data = 0.033\n",
            "OOBS Score =  13.715\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  28\n",
            "MSE on train data = 0.177\n",
            "OOBS Score =  13.517\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  29\n",
            "MSE on train data = 0.03\n",
            "OOBS Score =  10.953\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  30\n",
            "MSE on train data = 0.122\n",
            "OOBS Score =  14.839\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  31\n",
            "MSE on train data = 0.125\n",
            "OOBS Score =  15.258\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  32\n",
            "MSE on train data = 0.079\n",
            "OOBS Score =  10.284\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  33\n",
            "MSE on train data = 0.024\n",
            "OOBS Score =  14.973\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  34\n",
            "MSE on train data = 0.038\n",
            "OOBS Score =  15.256\n",
            "==============================\n",
            "==============================\n",
            "Iteration:  35\n",
            "MSE on train data = 0.054\n",
            "OOBS Score =  18.607\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "# repeat Task 1 35 times :\n",
        "train_mse_list = [] \n",
        "oobs_score_list = []\n",
        "for iteration in range (1 , 36):\n",
        "    list_input_data =[] \n",
        "    list_output_data =[] \n",
        "    list_selected_row= [] \n",
        "    list_selected_columns=[] \n",
        "    list_of_all_models = [] \n",
        "    list_predict = [] \n",
        "    oob_y_predict = [] \n",
        "    y_sample_predict = []\n",
        "  \n",
        "    for i in range(0,30):\n",
        "        final_sample_data, final_target_data, selected_rows, selected_columns = generating_samples(x,y)\n",
        "        # Append the info in the respective list.\n",
        "        list_input_data.append(final_sample_data) \n",
        "        list_output_data.append(final_target_data) \n",
        "        list_selected_row.append(selected_rows) \n",
        "        list_selected_columns.append(selected_columns)\n",
        "\n",
        "    #Write code for building regression trees\n",
        "    for i in range(0, 30):\n",
        "        input_data = list_input_data[i]\n",
        "        target_data = list_output_data[i]\n",
        "        classifier = DecisionTreeRegressor(max_depth=None,min_samples_split=2) \n",
        "        classifier.fit(input_data,target_data) \n",
        "        list_of_all_models.append(classifier)\n",
        "    \n",
        "    # write code for Calculating MSE :\n",
        "    for i in range(0,30):\n",
        "        pred_y = list_of_all_models[i].predict(x[:,list_selected_columns[i]]) \n",
        "        list_predict.append(pred_y)\n",
        "      # Calculating median for each data point from predicted y of each model.\n",
        "    final_y_predict = [] \n",
        "    for i in range(0 , 506):\n",
        "        med_y = []\n",
        "        for j in range(0 , 30):\n",
        "            med_y.append(list_predict[j][i]) \n",
        "        med = statistics.median(med_y) \n",
        "        final_y_predict.append(med)\n",
        "\n",
        "    # Calculating MSE :\n",
        "    mse = mean_squared_error(y, final_y_predict) \n",
        "    print(\"=\" * 30)\n",
        "    print(\"Iteration: \" , iteration) \n",
        "    print(\"MSE on train data =\" , round(mse,3)) \n",
        "    train_mse_list.append(mse)\n",
        "    # Calculating OOBS score\n",
        "    # iterating through each data point. \n",
        "    for i in range (0,506):\n",
        "        data = x[i]\n",
        "        for j in range(0,30):\n",
        "            if i not in list_selected_row[j]:\n",
        "                pred_y = list_of_all_models[j].predict(data[list_selected_columns[j]].reshape(1,-1)) \n",
        "                y_sample_predict.append(pred_y[0])\n",
        "        y_sample_predict_oobs = statistics.median(y_sample_predict) \n",
        "        y_sample_predict.clear() \n",
        "        oob_y_predict.append(y_sample_predict_oobs)\n",
        "\n",
        "    #Calculate OObs score now :\n",
        "    total_error = 0\n",
        "    for i in range(0,506):\n",
        "      error = y[i] - oob_y_predict[i] #Square error :\n",
        "      error = error * error \n",
        "      total_error += error\n",
        "    oobs_score = total_error/506 \n",
        "    print(\"OOBS Score = \" , round(oobs_score,3)) \n",
        "    print(\"=\" * 30) \n",
        "    oobs_score_list.append(oobs_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Confidence Interval"
      ],
      "metadata": {
        "id": "6FvyQab-vN9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://datatab.net/assets/tutorial/Confidence_interval_formula.png)"
      ],
      "metadata": {
        "id": "RAFSiOakzy0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting list to array\n",
        "import math\n",
        "train_mse = np.asarray(train_mse_list) \n",
        "oobs_score = np.asarray(oobs_score_list)\n",
        "\n",
        "# Compute mean\n",
        "mean_mse = np.mean(train_mse) \n",
        "mean_oobs = np.mean(oobs_score)\n",
        "\n",
        "#Compute Standard Deviation:\n",
        "std_mse = np.std(train_mse) \n",
        "std_oobs = np.std(oobs_score)\n",
        "\n",
        "#Compute Standard error:\n",
        "sqrt_n = math.sqrt(30) \n",
        "standard_error_mse = std_mse/sqrt_n \n",
        "standard_error_obs = std_oobs/sqrt_n\n",
        "\n",
        "#CI for MSE:\n",
        "lower_limit_mse = mean_mse - 2 * (standard_error_mse) \n",
        "upper_limit_mse = mean_mse + 2 * (standard_error_mse)\n",
        "print(\"=\" * 60)\n",
        "print(\"CI for MSE :\" , \"[\", lower_limit_mse , \",\" , upper_limit_mse,\"]\")\n",
        "\n",
        "#CI for MSE :\n",
        "lower_limit_oobs = mean_oobs - 2 * (standard_error_obs) \n",
        "upper_limit_oobs = mean_oobs + 2 * (standard_error_obs)\n",
        "print(\"CI for oob :\" , \"[\", lower_limit_oobs , \",\" , upper_limit_oobs,\"]\" ) \n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of5No2LtvWGD",
        "outputId": "51eef5f6-a583-4276-b55b-6092d224227e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CI for MSE : [ 0.05100328948561962 , 0.14635609957901446 ]\n",
            "CI for oob : [ 13.328001251278668 , 14.699926080114903 ]\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation / Interpretation of above Confidence Interval\n",
        "- By definition we know the interpretation of a 95% confidence interval for the population mean as - If repeated random samples were taken and the 95% confidence interval was computed for each sample, 95% of the intervals would contain the population mean.\n",
        "\n",
        "So in this case\n",
        "\n",
        "* MSE - There is a 95% chance that the confidence interval of (0.05100328948561962, 0.14635609957901446) contains the true population mean of MSE.\n",
        "* OOB Score - There is a 95% chance that the confidence interval of (13.328001251278668, 14.699926080114903) contains the true population mean of OOB Score.\n"
      ],
      "metadata": {
        "id": "GNY9wMve9rGa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTnJdiBVS_e"
      },
      "source": [
        "# <font color='blue'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxrvZqHV1Fr"
      },
      "source": [
        "<font color='orange'><b>Flowchart for Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyjwEJ62V6a6"
      },
      "source": [
        "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0emSwLL7VurD"
      },
      "source": [
        "![alt text](https://i.imgur.com/Y5cNhQk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29hjwKlWWDfo"
      },
      "source": [
        "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "i_pUlSD-VYD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc8938c-18ca-4d90-ede4-38fa009cf116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Predicted price for query point x_q is : [19.33333333]\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "x_q = np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
        "total_price = 0\n",
        "for m in range(0,30):\n",
        "  pred_y = list_of_all_models[m].predict(x_q[list_selected_columns[m]].reshape(1,-1))\n",
        "  total_price += pred_y\n",
        "\n",
        "# Not predicted price for the query point will be average of all prices predicted.\n",
        "predicted_price = total_price/30\n",
        "print(\"=\" * 50)\n",
        "print(\"Predicted price for query point x_q is :\" , predicted_price) \n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJHTGEZgWJjR"
      },
      "source": [
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdUi-0xWOJ9"
      },
      "source": [
        "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation from Task-1:\n",
        "- The Mean Squared Error (MSE) of 0.0338586956521739 and the Out-of-Bag (OOB) score of 11.253729518006153 are evaluation metrics used to assess the performance of a Random Forest model applied on the Boston housing dataset.\n",
        "\n",
        "- A lower MSE value indicates that the model is making fewer errors in predicting the target variable (in this case, housing prices). A MSE value of 0.0338 suggests that the model's predictions are relatively accurate.\n",
        "\n",
        "- The OOB score is an estimate of the model's performance on unseen data (i.e., data not used in training). An OOB score of 11.25 indicates that, on average, the model's predictions are off by about 11.25 units of the target variable.\n",
        "\n",
        "- In general, these values suggest that the Random Forest model is making accurate predictions and that the model's performance is good. However, these metrics should be compared with other evaluation metrics (such as R2 score) and the results of models trained with other algorithms to get a more comprehensive view of the model's performance."
      ],
      "metadata": {
        "id": "v7yUbHHj7FUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation from Task-2:\n",
        "\n",
        "- The Confidence Interval (CI) of the Mean Squared Error (MSE) [0.05100328948561962, 0.14635609957901446] and Out-of-Bag (OOB) score [13.328001251278668, 14.699926080114903] provides a range of values in which the true values of the metrics are likely to lie, given a certain level of confidence.\n",
        "\n",
        "- The CI of the MSE provides a range of values for the accuracy of the model's predictions. The interval [0.05100328948561962, 0.14635609957901446] suggests that with a certain level of confidence, the true MSE of the model lies between 0.05 and 0.15. A smaller MSE indicates more accurate predictions, so a CI that includes lower MSE values is preferred.\n",
        "\n",
        "- The CI of the OOB score provides a range of values for the performance of the model on unseen data. The interval [13.328001251278668, 14.699926080114903] suggests that with a certain level of confidence, the true OOB score of the model lies between 13.33 and 14.70. A lower OOB score indicates better performance, so a CI that includes lower OOB scores is preferred.\n",
        "\n",
        "- Overall, these values suggest that the model's performance on the Boston housing dataset is within the specified range of confidence. However, it is important to keep in mind that the intervals may be wide, indicating high variability or low confidence in the estimated values."
      ],
      "metadata": {
        "id": "obtyTQ6G8i7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation from Task-3:\n",
        "*(target variable(medv): median value of owner-occupied homes in \\$1000s.)*\n",
        "- The prediction value of 19.33333333 for the query point on the Boston Housing dataset using a Random Forest model suggests that the model is predicting a median housing price of approximately $19,333.33 (19.333.*$1000). However, it is important to note that this value is just one prediction and may not accurately represent the actual median housing price in the area.\n",
        "\n",
        "- In order to better understand the prediction, it would be necessary to examine other factors such as the accuracy of the model, the quality of the data used for training, and the specific features used for prediction. Additionally, it may be helpful to compare this prediction to actual median housing prices in the area to determine the accuracy of the prediction.\n"
      ],
      "metadata": {
        "id": "B-9_c0Sr8wRy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTxbDmjO7D61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "# **References:**\n",
        "\n",
        "The following links/blogs/resources are references which i referred While writing above code\n",
        "- https://www.kaggle.com/code/paulrohan2020/implementation-of-bootstrap-in-random-forest/notebook\n",
        "\n",
        "- https://github.com/tufts-ml-courses/comp135-20f-assignments/blob/master/labs/day15_Bootstrap_and_RandomForest.ipynb\n",
        "- https://github.com/selva86/datasets/blob/master/BostonHousing.csv\n",
        "- https://stats.stackexchange.com/questions/354336/what-happens-when-bootstrapping-isnt-used-in-sklearn-randomforestclassifier \n",
        "- ChatGPT\n",
        "- stackoverflow\n",
        "- Quora\n",
        "- Yotube\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sQPzPUMtBomR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJiom27dCjn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}